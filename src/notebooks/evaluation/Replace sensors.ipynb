{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d4c564-f72b-4472-aeb5-a01e1c2fc244",
   "metadata": {},
   "source": [
    "### Using clusters to replace sensor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"/Users/30064457/Work/simopt/aws/data/mae-clust.csv\")\n",
    "\n",
    "column_stats = df.describe()\n",
    "\n",
    "# Print mean +/- standard deviation of each column\n",
    "print(\"Mean +/- Standard Deviation of each column:\")\n",
    "for col in df.columns:\n",
    "    mean = column_stats.loc['mean', col]\n",
    "    std_dev = column_stats.loc['std', col]\n",
    "    print(f\"{col}: {mean:.2f} +/- {std_dev:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensor\tdate\tBase\tLinear\tCircular\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"rob_mae_all.csv\")\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Drop the 'sensor' column\n",
    "df_without_sensor = df.drop(columns=['sensor','date'])\n",
    "\n",
    "# Filter rows where Linear is greater than 0\n",
    "filtered_df = df_without_sensor[(df_without_sensor['Linear'] > 0)&(df_without_sensor['Base'] > 0) & (df_without_sensor['Base'] < 6)]\n",
    "\n",
    "df=filtered_df\n",
    "column_stats = df.describe()\n",
    "\n",
    "# Print mean +/- standard deviation of each column\n",
    "print(\"Mean +/- Standard Deviation of each column:\")\n",
    "for col in df.columns:\n",
    "    mean = column_stats.loc['mean', col]\n",
    "    std_dev = column_stats.loc['std', col]\n",
    "    print(f\"{col}: {mean:.2f} +/- {std_dev:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6be5c95-cac2-46e3-b014-c58c9a06f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "from io import StringIO\n",
    "from typing import Optional, List\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tools.eval_measures import rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a876e8-318c-4f04-9d64-0ec2db6c05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(bucket_name, object_key):\n",
    "    df = pd.read_csv(datapath+object_key, index_col=0, parse_dates=True)\n",
    "    return df\n",
    "\n",
    "# loads data from s3 csv\n",
    "def load_data_s3(bucket_name, object_key):\n",
    "    client = boto3.client('s3')\n",
    "    csv_obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "\n",
    "    df = pd.read_csv(StringIO(csv_string), index_col=0, parse_dates=True)\n",
    "    return df\n",
    "\n",
    "def get_training_set(df, evaluation_date: str, training_interval_hours: int, sm_station_name: str, features: List[str]):\n",
    "\n",
    "    df_subset = df.copy().loc[df.sm_station_name == sm_station_name]\n",
    "    end_datetime = np.datetime64(evaluation_date + \" 00:00:00\") - 1 \n",
    "    training_interval = np.timedelta64(training_interval_hours, 'h')\n",
    "    start_datetime = (end_datetime) - (training_interval)\n",
    "    df_subset = df_subset[str(start_datetime):str(end_datetime)]\n",
    "    df_subset['t'] = range(0, df_subset.shape[0])\n",
    "    cols_to_keep = ['t'] + features\n",
    "    df_subset = df_subset.loc[:, cols_to_keep]\n",
    "    return df_subset\n",
    "\n",
    "def get_prediction_interval(df, evaluation_date: str, sm_station_name: str, target_column):\n",
    "        \n",
    "    df_subset = df.copy().loc[df.sm_station_name == sm_station_name]\n",
    "    start_datetime = np.datetime64(evaluation_date + \" 00:00:00\") \n",
    "    end_datetime = start_datetime + np.timedelta64(23, 'h')\n",
    "    df_subset = df_subset[str(start_datetime):str(end_datetime)]\n",
    "    df_subset['t'] = range(0, df_subset.shape[0])\n",
    "    df_subset = df_subset.loc[:, ['t'] + target_column]\n",
    "\n",
    "    return df_subset\n",
    "    \n",
    "def create_train_test_sets(df, n_hrs, features, target):\n",
    "    train_test_sets_by_sensor = {\n",
    "        \"sm_station_1\": {}, \n",
    "        \"sm_station_2\": {} \n",
    "         \n",
    "        }\n",
    "    sm_station_names = df.sm_station_name.unique()\n",
    "    eval_dates = np.unique(df[df.is_evaluation_period == True].index.date)\n",
    "    for i in range(0, sm_station_names.shape[0]):\n",
    "        station_keys = list(train_test_sets_by_sensor.keys())\n",
    "        train_test_sets = {}\n",
    "        for date in eval_dates:\n",
    "            training_interval = get_training_set(df, str(date), training_interval_hours=n_hrs, sm_station_name = sm_station_names[i], features=features)\n",
    "            prediction_interval = get_prediction_interval(df, str(date), sm_station_name = sm_station_names[i], target_column=target)\n",
    "            train_test_sets[f\"{str(date)}\"] = {\"train_set\": training_interval, \n",
    "                                             \"test_set\": prediction_interval}\n",
    "    \n",
    "        train_test_sets_by_sensor[station_keys[i]] = train_test_sets\n",
    "    return train_test_sets_by_sensor\n",
    "    \n",
    "def plot_series(time, series, format=\"-\", start=0, end=None, title=None, label=None):\n",
    "    \"\"\"\n",
    "    Visualizes time series data\n",
    "\n",
    "    Args:\n",
    "      time (array of int) - contains the time steps\n",
    "      series (array of int) - contains the measurements for each time step\n",
    "      format - line style when plotting the graph\n",
    "      label - tag for the line\n",
    "      start - first time step to plot\n",
    "      end - last time step to plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dimensions of the graph figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if type(series) is tuple:\n",
    "\n",
    "        for series_num in series:\n",
    "            # Plot the time series data\n",
    "            plt.plot(time[start:end], series_num[start:end], format)\n",
    "\n",
    "    else:\n",
    "      # Plot the time series data\n",
    "      plt.plot(time[start:end], series[start:end], format)\n",
    "\n",
    "    # Label the x-axis\n",
    "    plt.xlabel(\"Time\")\n",
    "\n",
    "    # Label the y-axis\n",
    "    plt.ylabel(\"Soil Moisture\")\n",
    "    \n",
    "    # Label the title\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.legend(label)\n",
    "\n",
    "    # Overlay a grid on the graph\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Draw the graph on screen\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_diff(train, test):\n",
    "    # calculate change in soil moisture as sm_diff\n",
    "    train['sm_diff'] = train.sm_soil_moisture.diff()\n",
    "    test['sm_diff'] = test.sm_soil_moisture.diff()\n",
    "    test.sm_diff.iloc[0] = test.sm_soil_moisture.iloc[0] - train.sm_soil_moisture.iloc[-1]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def create_train_test(train, test, features=None):\n",
    "    if type(features) is tuple:\n",
    "        x_train = pd.DataFrame()\n",
    "        x_test = pd.DataFrame()\n",
    "        for i in features:\n",
    "            x_train[i] = train[i][1:]\n",
    "            x_test[i] = test[i]   \n",
    "    else:\n",
    "        x_train = train.bom_actual_precipitation_hourly[1:]\n",
    "        x_test = test.bom_actual_precipitation_hourly\n",
    "\n",
    "    y_train = train.sm_diff[1:]\n",
    "    y_test = test.sm_diff\n",
    "    \n",
    "    x_train = x_train.fillna(method='ffill').to_numpy()\n",
    "    y_train = y_train.fillna(method='ffill').to_numpy()\n",
    "\n",
    "    x_test = x_test.fillna(method='ffill').to_numpy()\n",
    "    y_test = y_test.fillna(method='ffill').to_numpy()\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def get_best_k(x_train, y_train): \n",
    "    mae_val = [] #to store rmse values for different k\n",
    "    for K in range(20):\n",
    "        K = K+1\n",
    "        model = neighbors.KNeighborsRegressor(n_neighbors = K) #, weights='distance')\n",
    "\n",
    "        model.fit(x_train[:-24], y_train[:-24])  #fit the model\n",
    "        pred=model.predict(x_train[-24:]) #make prediction on test set\n",
    "        error = tf.keras.metrics.mean_absolute_error(y_train[-24:], pred).numpy()\n",
    "        mae_val.append(error) #store rmse values\n",
    "    min_mae = min(mae_val)   \n",
    "    best_k = mae_val.index(min_mae)+1\n",
    "\n",
    "    return best_k\n",
    "\n",
    "# calculates final predicted sm values by adding predicted diff to the last training value\n",
    "def calc_final_pred(pred_diff, last_sm):\n",
    "    final_pred = []\n",
    "    for diff in pred_diff:\n",
    "        current_sm = last_sm + diff\n",
    "        last_sm = current_sm\n",
    "        final_pred.append(current_sm)\n",
    "    return final_pred\n",
    "\n",
    "def run_knn(train, test, features): \n",
    "    # std_scaler= StandardScaler()\n",
    "    train, test = calculate_diff(train, test)\n",
    "    \n",
    "    # create train and test sets using specified features\n",
    "    x_train, y_train, x_test, y_test = create_train_test(train, test,features)\n",
    "    # # scale values across diff features\n",
    "    # x_train = std_scaler.fit_transform(x_train)\n",
    "    # x_test = std_scaler.fit_transform(x_test)\n",
    "    \n",
    "    # get best k neighbours\n",
    "    best_k = get_best_k(x_train, y_train) \n",
    "\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = best_k) #, weights='distance')\n",
    "    model.fit(x_train, y_train)  #fit the model\n",
    "    pred_diff=model.predict(x_test) #make prediction on test set\n",
    "\n",
    "    last_sm = train.sm_soil_moisture[-1]\n",
    "    final_pred = calc_final_pred(pred_diff, last_sm)\n",
    "    mae = tf.keras.metrics.mean_absolute_error(test.sm_soil_moisture, final_pred).numpy()\n",
    "    mse = rmse(test.sm_soil_moisture.to_numpy(), final_pred)\n",
    "    # mse = tf.keras.metrics.mean_squared_error(test.sm_soil_moisture, final_pred).numpy()\n",
    "    return final_pred, mae, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a847de9-5745-4a9c-b80c-5edde0a5f8bb",
   "metadata": {},
   "source": [
    "Selects features which are loaded into train_test_sets_by_sensor. We do this to prune the overall DF into the features, dates and sensors we want to experiment with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874e8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfc = load_data('simpact-combined-dataset','simpact_combined_dataset.csv')\n",
    "# df = df.fillna(method='ffill')\n",
    "\n",
    "#dfc[\"vpd\"] = (0.6108 * np.exp((17.27 * df.bom_actual_temperature)/(df.bom_actual_temperature + 237.3))) * (1.0 - (df.bom_actual_relative_humidity / 100.0))\n",
    "# specify variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08957d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da644a2d-2ebe-436b-8998-b889783950cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "df = load_data('simpact-evaluation-dataset','simpact_evaluation_dataset.csv')\n",
    "#df = load_data('simpact_combined_for_eval','simpact_combined_for_eval.csv')\n",
    "#df = df.fillna(method='ffill')\n",
    "\n",
    "#df = load_data('simpact-combined-dataset','simpact_combined_dataset.csv')\n",
    "###### from train_test_set_create...\n",
    "\n",
    "unique_dates =  np.unique(df.index.date)\n",
    "last_index =  unique_dates.shape[0] -2\n",
    "mid_point = last_index / 2 \n",
    "mid_point_index = int(mid_point -1)\n",
    "\n",
    "start_date = np.unique(df.index.date)[mid_point_index]\n",
    "end_date = np.unique(df.index.date)[-2] \n",
    "\n",
    "\n",
    "interval = round((end_date - start_date).days /4) # get the interval that should be between each evaluation point (we want evaluation points that are evenly spaced)\n",
    "eval_date_indices = [mid_point_index, mid_point_index+(interval), mid_point_index+(interval*2), mid_point_index+(interval*3), last_index]\n",
    "\n",
    "\n",
    "eval_dates = unique_dates[eval_date_indices]\n",
    "\n",
    "# UPDATE November 20 2022: we need additional days with precipitation. We will manually select two types of conditions: one where there is a long dry period, followed by rain\n",
    "# and another day of rain where there is rainfall without a dry spell beforehand \n",
    "manual_dates = [np.datetime64(\"2022-07-02\"), np.datetime64(\"2022-07-22\")]\n",
    "eval_dates = np.append(eval_dates,manual_dates)\n",
    "\n",
    "df['is_evaluation_period'] = False\n",
    "\n",
    "for eval_date in eval_dates:\n",
    "     df.loc[(df.index.get_level_values('datetime').date == eval_date),'is_evaluation_period'] = True\n",
    "######\n",
    "df[\"vpd\"] = (0.6108 * np.exp((17.27 * df.bom_actual_temperature)/(df.bom_actual_temperature + 237.3))) * (1.0 - (df.bom_actual_relative_humidity / 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bc60a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fm_station_name</th>\n",
       "      <th>trh_sensor_name</th>\n",
       "      <th>sm_station_name</th>\n",
       "      <th>sm_soil_temperature</th>\n",
       "      <th>sm_soil_moisture</th>\n",
       "      <th>sm_longitude</th>\n",
       "      <th>sm_latitude</th>\n",
       "      <th>sm_soil_moisture_interpolated</th>\n",
       "      <th>sm_soil_moisture_is_interpolated</th>\n",
       "      <th>sm_soil_temperature_interpolated</th>\n",
       "      <th>...</th>\n",
       "      <th>fm_precipitation_intensity</th>\n",
       "      <th>bom_forecasted_temperature</th>\n",
       "      <th>bom_forecasted_relative_humidity</th>\n",
       "      <th>bom_forecasted_precipitation_quantitiy</th>\n",
       "      <th>bom_actual_temperature</th>\n",
       "      <th>bom_actual_relative_humidity</th>\n",
       "      <th>bom_actual_precipitation_cumulative</th>\n",
       "      <th>bom_actual_precipitation_hourly</th>\n",
       "      <th>is_evaluation_period</th>\n",
       "      <th>vpd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-10 00:00:00+00:00</th>\n",
       "      <td>WS400-UMB-457_1221</td>\n",
       "      <td>SENS0017-TRH-SOPA</td>\n",
       "      <td>SENS0095-SM-SOPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.0789</td>\n",
       "      <td>-33.84646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.237226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 00:00:00+00:00</th>\n",
       "      <td>WS400-UMB-457_1221</td>\n",
       "      <td>SENS0017-TRH-SOPA</td>\n",
       "      <td>SENS0098-SM-SOPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.0787</td>\n",
       "      <td>-33.84650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.237226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 01:00:00+00:00</th>\n",
       "      <td>WS400-UMB-457_1221</td>\n",
       "      <td>SENS0017-TRH-SOPA</td>\n",
       "      <td>SENS0095-SM-SOPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.0789</td>\n",
       "      <td>-33.84646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.575534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 01:00:00+00:00</th>\n",
       "      <td>WS400-UMB-457_1221</td>\n",
       "      <td>SENS0017-TRH-SOPA</td>\n",
       "      <td>SENS0098-SM-SOPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.0787</td>\n",
       "      <td>-33.84650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.575534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 02:00:00+00:00</th>\n",
       "      <td>WS400-UMB-457_1221</td>\n",
       "      <td>SENS0017-TRH-SOPA</td>\n",
       "      <td>SENS0095-SM-SOPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.0789</td>\n",
       "      <td>-33.84646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.3</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.937286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fm_station_name    trh_sensor_name  \\\n",
       "datetime                                                           \n",
       "2022-05-10 00:00:00+00:00  WS400-UMB-457_1221  SENS0017-TRH-SOPA   \n",
       "2022-05-10 00:00:00+00:00  WS400-UMB-457_1221  SENS0017-TRH-SOPA   \n",
       "2022-05-10 01:00:00+00:00  WS400-UMB-457_1221  SENS0017-TRH-SOPA   \n",
       "2022-05-10 01:00:00+00:00  WS400-UMB-457_1221  SENS0017-TRH-SOPA   \n",
       "2022-05-10 02:00:00+00:00  WS400-UMB-457_1221  SENS0017-TRH-SOPA   \n",
       "\n",
       "                            sm_station_name  sm_soil_temperature  \\\n",
       "datetime                                                           \n",
       "2022-05-10 00:00:00+00:00  SENS0095-SM-SOPA                  NaN   \n",
       "2022-05-10 00:00:00+00:00  SENS0098-SM-SOPA                  NaN   \n",
       "2022-05-10 01:00:00+00:00  SENS0095-SM-SOPA                  NaN   \n",
       "2022-05-10 01:00:00+00:00  SENS0098-SM-SOPA                  NaN   \n",
       "2022-05-10 02:00:00+00:00  SENS0095-SM-SOPA                  NaN   \n",
       "\n",
       "                           sm_soil_moisture  sm_longitude  sm_latitude  \\\n",
       "datetime                                                                 \n",
       "2022-05-10 00:00:00+00:00               NaN      151.0789    -33.84646   \n",
       "2022-05-10 00:00:00+00:00               NaN      151.0787    -33.84650   \n",
       "2022-05-10 01:00:00+00:00               NaN      151.0789    -33.84646   \n",
       "2022-05-10 01:00:00+00:00               NaN      151.0787    -33.84650   \n",
       "2022-05-10 02:00:00+00:00               NaN      151.0789    -33.84646   \n",
       "\n",
       "                           sm_soil_moisture_interpolated  \\\n",
       "datetime                                                   \n",
       "2022-05-10 00:00:00+00:00                            NaN   \n",
       "2022-05-10 00:00:00+00:00                            NaN   \n",
       "2022-05-10 01:00:00+00:00                            NaN   \n",
       "2022-05-10 01:00:00+00:00                            NaN   \n",
       "2022-05-10 02:00:00+00:00                            NaN   \n",
       "\n",
       "                           sm_soil_moisture_is_interpolated  \\\n",
       "datetime                                                      \n",
       "2022-05-10 00:00:00+00:00                             False   \n",
       "2022-05-10 00:00:00+00:00                             False   \n",
       "2022-05-10 01:00:00+00:00                             False   \n",
       "2022-05-10 01:00:00+00:00                             False   \n",
       "2022-05-10 02:00:00+00:00                             False   \n",
       "\n",
       "                           sm_soil_temperature_interpolated  ...  \\\n",
       "datetime                                                     ...   \n",
       "2022-05-10 00:00:00+00:00                               NaN  ...   \n",
       "2022-05-10 00:00:00+00:00                               NaN  ...   \n",
       "2022-05-10 01:00:00+00:00                               NaN  ...   \n",
       "2022-05-10 01:00:00+00:00                               NaN  ...   \n",
       "2022-05-10 02:00:00+00:00                               NaN  ...   \n",
       "\n",
       "                           fm_precipitation_intensity  \\\n",
       "datetime                                                \n",
       "2022-05-10 00:00:00+00:00                         0.0   \n",
       "2022-05-10 00:00:00+00:00                         0.0   \n",
       "2022-05-10 01:00:00+00:00                         0.0   \n",
       "2022-05-10 01:00:00+00:00                         0.0   \n",
       "2022-05-10 02:00:00+00:00                         0.0   \n",
       "\n",
       "                           bom_forecasted_temperature  \\\n",
       "datetime                                                \n",
       "2022-05-10 00:00:00+00:00                         NaN   \n",
       "2022-05-10 00:00:00+00:00                         NaN   \n",
       "2022-05-10 01:00:00+00:00                         NaN   \n",
       "2022-05-10 01:00:00+00:00                         NaN   \n",
       "2022-05-10 02:00:00+00:00                         NaN   \n",
       "\n",
       "                           bom_forecasted_relative_humidity  \\\n",
       "datetime                                                      \n",
       "2022-05-10 00:00:00+00:00                               NaN   \n",
       "2022-05-10 00:00:00+00:00                               NaN   \n",
       "2022-05-10 01:00:00+00:00                               NaN   \n",
       "2022-05-10 01:00:00+00:00                               NaN   \n",
       "2022-05-10 02:00:00+00:00                               NaN   \n",
       "\n",
       "                           bom_forecasted_precipitation_quantitiy  \\\n",
       "datetime                                                            \n",
       "2022-05-10 00:00:00+00:00                                     NaN   \n",
       "2022-05-10 00:00:00+00:00                                     NaN   \n",
       "2022-05-10 01:00:00+00:00                                     NaN   \n",
       "2022-05-10 01:00:00+00:00                                     NaN   \n",
       "2022-05-10 02:00:00+00:00                                     NaN   \n",
       "\n",
       "                           bom_actual_temperature  \\\n",
       "datetime                                            \n",
       "2022-05-10 00:00:00+00:00                    18.7   \n",
       "2022-05-10 00:00:00+00:00                    18.7   \n",
       "2022-05-10 01:00:00+00:00                    21.1   \n",
       "2022-05-10 01:00:00+00:00                    21.1   \n",
       "2022-05-10 02:00:00+00:00                    21.3   \n",
       "\n",
       "                           bom_actual_relative_humidity  \\\n",
       "datetime                                                  \n",
       "2022-05-10 00:00:00+00:00                          89.0   \n",
       "2022-05-10 00:00:00+00:00                          89.0   \n",
       "2022-05-10 01:00:00+00:00                          77.0   \n",
       "2022-05-10 01:00:00+00:00                          77.0   \n",
       "2022-05-10 02:00:00+00:00                          63.0   \n",
       "\n",
       "                           bom_actual_precipitation_cumulative  \\\n",
       "datetime                                                         \n",
       "2022-05-10 00:00:00+00:00                                  0.0   \n",
       "2022-05-10 00:00:00+00:00                                  0.0   \n",
       "2022-05-10 01:00:00+00:00                                  0.0   \n",
       "2022-05-10 01:00:00+00:00                                  0.0   \n",
       "2022-05-10 02:00:00+00:00                                  0.0   \n",
       "\n",
       "                           bom_actual_precipitation_hourly  \\\n",
       "datetime                                                     \n",
       "2022-05-10 00:00:00+00:00                              0.0   \n",
       "2022-05-10 00:00:00+00:00                              0.0   \n",
       "2022-05-10 01:00:00+00:00                              0.0   \n",
       "2022-05-10 01:00:00+00:00                              0.0   \n",
       "2022-05-10 02:00:00+00:00                              0.0   \n",
       "\n",
       "                           is_evaluation_period       vpd  \n",
       "datetime                                                   \n",
       "2022-05-10 00:00:00+00:00                 False  0.237226  \n",
       "2022-05-10 00:00:00+00:00                 False  0.237226  \n",
       "2022-05-10 01:00:00+00:00                 False  0.575534  \n",
       "2022-05-10 01:00:00+00:00                 False  0.575534  \n",
       "2022-05-10 02:00:00+00:00                 False  0.937286  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "811cad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip to dfc then replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0dfbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables \n",
    "# features = ['sm_soil_moisture', 'bom_forecasted_temperature', 'bom_forecasted_relative_humidity', 'bom_forecasted_precipitation_quantitiy']\n",
    "# target = ['sm_soil_moisture', 'bom_forecasted_temperature', 'bom_forecasted_relative_humidity', 'bom_forecasted_precipitation_quantitiy']\n",
    "data_features = ['sm_soil_moisture', 'bom_actual_precipitation_hourly', 'bom_actual_temperature', 'bom_actual_relative_humidity', 'vpd'] # features to include in training set\n",
    "target = ['sm_soil_moisture', 'bom_actual_precipitation_hourly', 'bom_actual_temperature', 'bom_actual_relative_humidity', 'vpd'] # the column with the variable we want to predict\n",
    "n_hrs = 400 # the training interval in hours\n",
    "\n",
    "# run the function \n",
    "train_test_sets_by_sensor = create_train_test_sets(df, n_hrs, data_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.is_evaluation_period == False].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d324f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SENS0095-SM-SOPA', 'SENS0098-SM-SOPA', 'SENS0020-SM-SOPA',\n",
       "       'SENS0107-SM-SOPA', 'SENS0152-SM-SOPA'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sm_station_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd5af618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SENS0017-TRH-SOPA', 'SENS0007-TRH-SOPA', 'SENS0028-TRH-SOPA',\n",
       "       'SENS0029-TRH-SOPA'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trh_sensor_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc444e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2022, 7, 28) datetime.date(2022, 8, 17)\n",
      " datetime.date(2022, 9, 6) datetime.date(2022, 9, 26)\n",
      " datetime.date(2022, 10, 17) datetime.date(2022, 7, 2)\n",
      " datetime.date(2022, 7, 22)]\n"
     ]
    }
   ],
   "source": [
    "print(eval_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c685ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfc = load_data('simpact-combined-dataset','simpact_combined_dataset.csv')\n",
    "dfc = load_data('simpact_combined_for_eval','simpact_combined_for_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b514b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfc['sm_station_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = dfc.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d4a26-7fa9-4220-87e4-5bc7a68e1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_list = ['sm_station_1', 'sm_station_2', 'sm_station_3', 'sm_station_4', 'sm_station_5']\n",
    "# dates = ['2022-07-02', '2022-07-22', '2022-07-28', '2022-08-17', '2022-09-06', '2022-09-26', '2022-10-17']\n",
    "\n",
    "#sensor_list = list(train_test_sets_by_sensor.keys())\n",
    "#dates = list(train_test_sets_by_sensor[sensor_list[0]].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run either A here - single replace for single sensor\n",
    "def replace_sensor_values(df, dfc, sm_station_name1, sm_station_name2):\n",
    "    # Filter dataframes to get only relevant rows for each sensor name\n",
    "    df_sensor1 = df[df['sm_station_name'] == sm_station_name1]\n",
    "    dfc_sensor2 = dfc[dfc['sm_station_name'] == sm_station_name2]\n",
    "    \n",
    "    # Check if both sensor names exist in the dataframes\n",
    "    if df_sensor1.empty or dfc_sensor2.empty:\n",
    "        print(\"One or both sensor names not found in the dataframes.\")\n",
    "        return df  # Return original dataframe if either sensor name is not found\n",
    "    \n",
    "    # Replace values in df with corresponding values from dfc\n",
    "    df.loc[df['sm_station_name'] == sm_station_name1, 'sm_soil_moisture'] = dfc_sensor2['sm_soil_moisture'].values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = replace_sensor_values(df, dfc, 'SENS0098-SM-SOPA', 'SENS0099-SM-SOPA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or B here - replace single sensor with multi sensor \n",
    "def replace_sensor_values_avg(df, dfc, sm_station_name1, sm_station_name2_list):\n",
    "    # Filter dataframe to get only relevant rows for sm_station_name1\n",
    "    df_sensor1 = df[df['sm_station_name'] == sm_station_name1]\n",
    "    \n",
    "    # Check if sm_station_name1 exists in the dataframe\n",
    "    if df_sensor1.empty:\n",
    "        print(f\"Sensor name '{sm_station_name1}' not found in the dataframe.\")\n",
    "        return df  # Return original dataframe if sensor name is not found\n",
    "    \n",
    "    # Filter dataframe to get relevant rows for sm_station_name2_list\n",
    "    dfc_sensor2 = dfc[dfc['sm_station_name'].isin(sm_station_name2_list)]\n",
    "    \n",
    "    # Check if any of the sm_station_name2_list sensors are not found in the dfc\n",
    "    missing_sensors = set(sm_station_name2_list) - set(dfc_sensor2['sm_station_name'])\n",
    "    if missing_sensors:\n",
    "        print(f\"Some sensor names in {missing_sensors} not found in dfc.\")\n",
    "        return df  # Return original dataframe if any sensor name is not found in dfc\n",
    "    \n",
    "    # Calculate the average of corresponding values from dfc for sm_station_name2_list\n",
    "    avg_values = dfc_sensor2.groupby(dfc_sensor2.index)['sm_soil_moisture'].mean()\n",
    "    \n",
    "    # Replace values in df with the average values\n",
    "    df.loc[df['sm_station_name'] == sm_station_name1, 'sm_soil_moisture'] = avg_values.reindex(df_sensor1.index, fill_value=0).values\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Replace values of sensor 'SENS0020-SM-SOPA' in df with average values of sensors in the list ['SENS0107-SM-SOPA', 'SENS0152-SM-SOPA'] in dfc\n",
    "\n",
    "# Example usage:\n",
    "# Replace values of sensor 'SENS0020-SM-SOPA' in df with average values of sensors in the list ['SENS0107-SM-SOPA', 'SENS0152-SM-SOPA'] in dfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sensor_names(sensor_numbers):\n",
    "    formatted_sensor_names = []\n",
    "    for sensor_number in sensor_numbers:\n",
    "        # Pad the sensor number with leading zeros to make it four digits wide\n",
    "        padded_sensor_number = str(sensor_number).zfill(4)\n",
    "        # Format the sensor name\n",
    "        sensor_name = f'SENS{padded_sensor_number}-SM-SOPA'\n",
    "        formatted_sensor_names.append(sensor_name)\n",
    "    return formatted_sensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cluster 10 of k-shape k=17\n",
    "#Some sensor names in {'SENS0233-SM-SOPA'} not found in dfc.\n",
    "\n",
    "#df = replace_sensor_values_avg(df, dfc, 'SENS0098-SM-SOPA', ['SENS0039-SM-SOPA', 'SENS0155-SM-SOPA', 'SENS0191-SM-SOPA'])\n",
    "df = replace_sensor_values_avg(df, dfc, 'SENS0098-SM-SOPA', format_sensor_names([39,155,191]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cluster 19 of k-shape k=17\n",
    "#[14,19,24,42,150,209,226,229,230]\n",
    "#Some sensor names in {'SENS0150-SM-SOPA', 'SENS0226-SM-SOPA', 'SENS0014-SM-SOPA', 'SENS0229-SM-SOPA', 'SENS0230-SM-SOPA'} not found in dfc.\n",
    "df = replace_sensor_values_avg(df, dfc, 'SENS0107-SM-SOPA', format_sensor_names([19,24,42,209]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ff213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e26feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cluster 16 of dtw k=21\n",
    "#[17,19,73,118,119,134,137,185,192,203,220]\n",
    "\n",
    "#Some sensor names in {'SENS0118-SM-SOPA', 'SENS0220-SM-SOPA', 'SENS0185-SM-SOPA'} not found in dfc.\n",
    "df = replace_sensor_values_avg(df, dfc, 'SENS0098-SM-SOPA', format_sensor_names([17,19,73,119,134,137,192,203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cluster 12 of dtw k=21\n",
    "#[24,150,175,230,243]\n",
    "#Some sensor names in {'SENS0243-SM-SOPA', 'SENS0150-SM-SOPA', 'SENS0230-SM-SOPA'} not found in dfc.\n",
    "df = replace_sensor_values_avg(df, dfc, 'SENS0107-SM-SOPA', format_sensor_names([24,175]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28945207",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = ['sm_soil_moisture', 'bom_actual_precipitation_hourly', 'bom_actual_temperature', 'bom_actual_relative_humidity', 'vpd'] # features to include in training set\n",
    "target = ['sm_soil_moisture', 'bom_actual_precipitation_hourly', 'bom_actual_temperature', 'bom_actual_relative_humidity', 'vpd'] # the column with the variable we want to predict\n",
    "n_hrs = 400 # the training interval in hours\n",
    "\n",
    "# run the function \n",
    "train_test_sets_by_sensor = create_train_test_sets(df, n_hrs, data_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensor_list = ['sm_station_1', 'sm_station_2', 'sm_station_3', 'sm_station_4', 'sm_station_5']\n",
    "#dates = ['2022-07-02', '2022-07-22', '2022-07-28', '2022-08-17', '2022-09-06', '2022-09-26', '2022-10-17']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbbc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensor_list = list(train_test_sets_by_sensor.keys())\n",
    "#dates = list(train_test_sets_by_sensor[sensor_list[0]].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48487c-d0dd-4d95-bd86-3726bcfb50d2",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d0eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721ce9-f62b-4d42-b02b-7ed9fca97ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'sensor':[], 'date':[], 'mae':[]}\n",
    "# features = ('bom_forecasted_temperature', 'bom_forecasted_relative_humidity', 'bom_forecasted_precipitation_quantitiy')\n",
    "\n",
    "train_features = ('bom_actual_precipitation_hourly', 'vpd') #'bom_actual_temperature', 'bom_actual_relative_humidity') #, 'sm_soil_moisture')\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "for sensor in sensor_list:\n",
    "    # fig, ax = plt.subplots(5, sharex='col', sharey='row', figsize=(15,15))\n",
    "    i = 0\n",
    "    for date in dates:\n",
    "        # adding break to skipp empty set\n",
    "        # if sensor =='sm_station_4' and (date == '2022-10-17' or date == '2022-07-28'):\n",
    "        #     break\n",
    "        results['sensor'].append(sensor)\n",
    "        results['date'].append(date)\n",
    "        \n",
    "        train = train_test_sets_by_sensor[sensor][date]['train_set']\n",
    "        train = train.fillna(method='ffill')\n",
    "\n",
    "        test = train_test_sets_by_sensor[sensor][date]['test_set']\n",
    "        test = test.fillna(method='ffill')\n",
    "        \n",
    "        try:\n",
    "            final_pred, mae, mse = run_knn(train, test, train_features)\n",
    "            mae_list.append(mae)\n",
    "            mse_list.append(mse)\n",
    "            # results['mae'].append(mae)\n",
    "            plot_series(test.t, (test.sm_soil_moisture, final_pred), title = sensor + ' ' + date, label = ('ground truth', 'forecast'))\n",
    "            # plot_series(test.t, (test.bom_actual_precipitation_hourly, test.bom_actual_temperature, test.bom_actual_relative_humidity), label = features)\n",
    "        except:\n",
    "            pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001cc50-184f-4b1e-a02f-b2267c59eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = pd.DataFrame(results)\n",
    "# # print(df_persistance_1_results.head())\n",
    "# df_results['mae'].mean()\n",
    "sum(mae_list)/len(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c79b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae1s=pd.DataFrame(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mae1s.iloc[14,0]=2.061128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maea=mae1s.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270da8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maea['ReplaceD107']=mae1s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maea=maea.drop(columns=['Replace1', 'Replace2', 'ReplaceK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92728512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maea.rename(columns={\"ReplaceK1\": \"ReplaceK98\", \"ReplaceD1\": \"ReplaceD98\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = pd.concat([maea['base'], maea['ReplaceK107'], maea['ReplaceD107']], axis=1, keys=['Base', 'ReplaceK107', 'ReplaceD107'])\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=data_to_plot)\n",
    "\n",
    "# Add labels to the axes and a title\n",
    "plt.xlabel('')\n",
    "plt.ylabel('MAE Values')\n",
    "plt.title('MAE Values for Base and Two Sensor Replacements')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0198550",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mae_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6cb0c-a01f-4b78-901b-fd45e2f23646",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {'RMSE': mse_list, 'MAE': mae_list}\n",
    "pd.DataFrame(results_dict).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dfc - don't run as already done and csv created\n",
    "df=dfc.copy()\n",
    "unique_dates =  np.unique(df.index.date)\n",
    "last_index =  unique_dates.shape[0] -2\n",
    "mid_point = last_index / 2 \n",
    "mid_point_index = int(mid_point -1)\n",
    "\n",
    "start_date = np.unique(df.index.date)[mid_point_index]\n",
    "end_date = np.unique(df.index.date)[-2] \n",
    "\n",
    "\n",
    "interval = round((end_date - start_date).days / 4) # get the interval that should be between each evaluation point (we want evaluation points that are evenly spaced)\n",
    "eval_date_indices = [mid_point_index, mid_point_index+(interval), mid_point_index+(interval*2), mid_point_index+(interval*3), last_index]\n",
    "\n",
    "\n",
    "eval_dates = unique_dates[eval_date_indices]\n",
    "\n",
    "# UPDATE November 20 2022: we need additional days with precipitation. We will manually select two types of conditions: one where there is a long dry period, followed by rain\n",
    "# and another day of rain where there is rainfall without a dry spell beforehand \n",
    "manual_dates = [np.datetime64(\"2022-07-02\"), np.datetime64(\"2022-07-22\")]\n",
    "eval_dates = np.append(eval_dates,manual_dates)\n",
    "\n",
    "df['is_evaluation_period'] = False\n",
    "\n",
    "for eval_date in eval_dates:\n",
    "     df.loc[(df.index.get_level_values('datetime').date == eval_date),'is_evaluation_period'] = True\n",
    "######\n",
    "df[\"vpd\"] = (0.6108 * np.exp((17.27 * df.bom_actual_temperature)/(df.bom_actual_temperature + 237.3))) * (1.0 - (df.bom_actual_relative_humidity / 100.0))\n",
    "# specify variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913662c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(datapath+'simpact_combined_for_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74b782-afa8-49c6-bc1f-4da6fed7ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_sensor_locations(df_unique, sensor_list):\n",
    "    # Filter dataframe to include only sensors from the provided list\n",
    "    df_filtered = df_unique[df_unique['sm_station_name'].isin(sensor_list)]\n",
    "    \n",
    "    # Create a map with initial centering and zoom level based on all sensor locations\n",
    "    map_sensor_locations = folium.Map(location=[df_filtered['sm_latitude'].mean(), df_filtered['sm_longitude'].mean()], zoom_start=10)\n",
    "    \n",
    "    # Add markers for each sensor location with sensor number as label\n",
    "    for index, row in df_filtered.iterrows():\n",
    "        folium.Marker([row['sm_latitude'], row['sm_longitude']], popup=row['sm_station_name'], \n",
    "                      tooltip=row['sensor_number']).add_to(map_sensor_locations)\n",
    "    \n",
    "    # Display the map directly in the Jupyter Notebook\n",
    "    display(map_sensor_locations)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df_unique is your dataframe and sensor_list is a list of sensors\n",
    "# Replace ['SENS0020-SM-SOPA', 'SENS0107-SM-SOPA', 'SENS0152-SM-SOPA'] with your actual list of sensors\n",
    "#sensor_list = ['SENS0020-SM-SOPA', 'SENS0028-SM-SOPA', 'SENS0063-SM-SOPA', 'SENS0066-SM-SOPA']\n",
    "\n",
    "sensor_list = ['SENS0107-SM-SOPA', 'SENS0016-SM-SOPA', 'SENS0114-SM-SOPA', 'SENS0125-SM-SOPA', 'SENS0126-SM-SOPA']\n",
    "plot_sensor_locations(dfc_unique, sensor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b7ed2-7e54-4665-a2d6-ba59c75550f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list = ['SENS0098-SM-SOPA', 'SENS0099-SM-SOPA']\n",
    "map_sensor_locations = plot_sensor_locations(dfc_unique, sensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90d920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
